<html>
<head>
<title>人工智能原理</title>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<link rel="stylesheet" href="../../../css/text.css" type="text/css">
</head>
<body bgcolor="#FFFFFF" class="bg">
<table width="100%" border="0" cellspacing="0" cellpadding="0">
  <tr>
    <td class=text> <b> 　　- 信息处理的并行性；</b><br>
      　　神经网络结构决定了其信号并行处理的特性。这种结构本身所带来的并行性特性是其它系统模型所可望不可及的。虽然目前已有一些神经网络硬件化的研究，有成果公布，也还是实验室水平，没有真正开发成神经网络芯片。因此，大多数神经网络系统还是用计算机来仿真实现，事实上是使用串行来代替并行的。但是，我们相信随着大规模集成电路技术的发展，不久的将来将会有神经网络芯片诞生，有真正的神经网络系统问世，具有无可比拟的信号处理速度，为人类信息科学的进步开辟新的途径。<br>
      <b>　　- 知识的分布存储；</b><br>
      　　传统的人工智能系统的知识大多是以知识库的形式储存的，比较清晰，便于管理和修改。但是，神经网络通过设计，或通过学习得到的知识是以各个神经元的连接权的值来表现的。从形式上看是分布在网络的各个角落，同时，没有任何显示的信息可以阅读，对于人类来说是完全不透明的，无法理解的，更谈不上管理和修改。这一点对于习惯于对自己设计的系统了如指掌的人来说，不是一件好事。<br>
      <b>　　- 对于系统本身及环境的变化的容错性；</b><br>
      　　由于系统知识的分布式处理，使得神经网络对于样本的错误等原因引起的环境干扰有很强的容错能力。因为错误也是分布的，不会集中体现在某一个地方，也就不会造成突出的影响。反之变形的实际样本，也不会由于部分不匹配而产生很大的误差。另外，环境噪声也可以理解为样本的变形，同样可以有很好的鲁棒性。<br>
      <b>　　- 学习能力</b><br>
      　　神经网络的学习方法与传统的人工智能机器学习的方法完全不同。即使与实例学习方法相比较也有本质上的差别。同样是在提交的学习样本的指导下进行学习，实例学习是根据样本修改已有的（或假设的）规则空间中的规则，规则内容、范围、可修改程度完全是人规定的。而大多数神经网络模型的学习是从随机初始值开始的，理论上初始值不影响最终结果。整个过程无人工干预，系统通过学习发生的变化也无从察看。因此，也有人称神经网络是一个黑盒子。</td>
  </tr>
</table>
</body>
</html>
