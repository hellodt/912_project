<html>
<head>
<title>Untitled Document</title>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<link rel="stylesheet" href="../../../../../css/text.css" type="text/css">
</head>

<body bgcolor="#FFFFFF" text="#000000" background="../../../../../images/templater/pop/di.gif">
<center><table width="95%" border="0" cellspacing="0" cellpadding="0">
  <tr>
      <td class=text> <b>问答题答案</b> <br>
<br>
        <b>问答第1题</b><br>
        多媒体计算机的关键技术是： ①视频音频信号获取技术； ②多媒体数据压缩编码和解码技术； ③视频音频数据的实时处理和特技； ④视频音频数据的输出技术。 
        多媒体计算机的主要应用领域： ①多媒体数据库和基于内容的检索； ②多媒体通信； ③多媒体创作工具。 <br>
        <br>
        <b>问答第2题</b><br>
        计算机综合处理多媒体信息：文本、图形、图像、音频和视频，使多种信息建立逻辑连接、集成为一个系统并具有交互性。 多媒体计算机从开发、生产厂商及应用的角度可分为两大类：家电制造 
        厂商研制的电视计算机 （Teleputer ）和计算机制造厂商研制的计算机电视（Compuvision）。 <br>
        <br>
        <b>问答第3题</b><br>
        MIDI是乐器数字接口(Musical Instrument Digital Interface)的缩写，它初始建于1982年，MIDI泛指数字乐器接口国际标准。标准的多媒体PC平台能够通过内部合成器或连到计算机端口的外部合成器播放MIDI文件。MIDI标准规定了不同厂家的电子乐器与计算机连接的电缆和硬件。它还指定了从一个装置传送数据到另一个装置的通信协议。这样，任何电子乐器，只要有处理MIDI信息的处理器和适当的硬件接口都能变成MIDI装置。 
        MIDI间靠这个接口传递消息(massage)，消息是乐谱(Score)的数字描述。乐谱由音符序列、定时和合成音色(Patches)的乐器定义所组成。当一组MIDI消息通过音乐合成芯片演奏时，合成器解释这些符号，并产生音乐。 
        <br>
        <br>
        <b>问答第4题</b><br>
        彩色全电视信号数字化后，得到数字式彩色全电视信号，一路经过数字式彩色副载波陷波滤波器，得到数字式色差信号U V ；再经过数字式U V解调电路，分别得到数字式U和V信号，这就是彩色全电视信号的数字解码。<br>
        <br>
        <b>问答第5题</b><br>
        Intel和IBM研制开发的Ⅱ型DVI系统，荣获了"Comdex 91"最佳多媒体产品奖和最佳展示奖。系统中首次引进视频音频引擎AVE(Audio 
        Video Engine)的概念。AVE是由视频子系统、音频子系统、彩色键连子系统、视频音频总线、获取子系统、CD-ROM子系统及主机接口子系统七部分组成。<br>
        <br>
        <b>问答第6题</b><br>
        它是Ⅱ型DVI系统的软件。称之为视频音频核AVK(Audio Video Kernel)，它可以在Windows环境下工作。也可在不同操作系统支持环境下工作。它具备多层模块化结构的特点，共分四层：最下层是象素处理器微码子程序的集合，称之为"微码引擎"；第二层是视频音频驱动器AVD(Audio/Video 
        Driver)；第三层是视频音频库AVL(Audio/Video Library)；最上层是特定支撑环境层，它的功能是读写数据到主文件系统；把AVK集成到Windows支持的环境中。<br>
        <br>
        <b>问答第7题</b><br>
        MPEG(Moving Picture Experts Group)运动图像专家组，在国际标准化组织ISO/IEC的领导下，从1988年MPEG委员会开始活动，1990年提出一个MPEG标准草案，1991年底提出了用于数字存储媒体的位率为1.5Mbps的运动图像及其伴音的压缩编码方案，为ISO/IEC 
        11172号建议，并于1992年正式通过，定名为MPEG-1。此后于1993年11月在汉城会议（ISO/IECJTCI/SC29/WG11）上正式通过了ISO/13813，定名为MPEG-II标准。MPEG1和MPEG2与JPEG和H.261有很多相似之处，它们也是采用了DCT、量化、行程编码和熵编码以及帧间预测和运动补偿。<br>
        <br>
        <b>问答第8题</b><br>
        离散余弦变换（DCT --Discrete Cosine Transform）是傅里叶变换的一种特殊情况。在傅里叶级数展开式中，被展开的函数是实偶函数时，其傅里叶级数中只包含余弦项，称之为余弦变换。离散余弦变换的特性和K－L变换比较接近，但是DCT计算复杂性适中，又具有可分离特性，还有快速算法，所以被广泛地用在图像数据压缩编码算法中，如JPEG、MPEG-1、MPEG-2及H.261等压缩编码国际标准都采用了离散余弦变换编码算法。<br>
        <br>
        <b>问答第9题</b><br>
        1996年3月5日Intel公司首次对外公布了MMX技术，它是由设在以色列海 的Intel实验室完成的，1997年1月9日Intel公司对外正式推出含有MMX技术，具有多媒体扩充指令集的多功能奔腾处理器P55C，1997年5月Intel又进一步推出具有MMX技术的P6奔腾芯片，主频可达300MHZ的PentiumⅡ 
        300，进一步提高了性能。MMX的核心技术是：新的数据类型、扩充的饱和型运算方式、扩充的57条新指令及与IA(Intel Architecture)结构的全兼容性。<br>
        <br>
        <b>问答第10题</b><br>
        对于传统的数据库可以通过数字和关键词进行检索。但是对于多媒体数据库，它存有大量的声、文、图、动画和视频信息，光通过数字和文字进行检索显得有些不足，提出基于多媒体数据的内容进行检索，这就是基于内容检索（Content-Based 
        Retrieval）。例如：对于图像数据库可以通过形状、主颜色、纹理及轮廓等特征进行检索。基于内容检索系统由下述几部分组成：目标标识、特征提取、数据库（媒体库、特征库、知识库）、检索引擎及索引/过滤器等。<br>
        <br>
        <b>问答第11题</b><br>
        多媒体技术促进了通信、娱乐和计算机的融合，主要体现在以下三个方面： ①多媒体技术是解决常规电视数字化及高清晰度电视（HDTV）切实可行的方案。采用多媒体计算机技术制造HDTV，它可支持任意分辨率的输出，输入输出分辨率可以独立，输出分辨率可以任意变化，可以用任意窗口尺寸输出。与此同时，它还赋予HDTV很多新的功能 
        ，如图形功能，视频音频特技以及交互式功能。多媒体计算机技术在常规电视和高清晰度电视的影视节目制作中的应用可分成两个层次。一是影视画面的制作：采用计算机软件生成二维、三维动画画面；摄像机在摄制真实的影视画面后采用数字图像处理技术制作影视特技画面，最后是采用计算机将生成和实时结合用图像处理技术制作影视特技画面。另一个层次是影视后期制作，如现在常用的数字式非线性编辑器，实质上是一台多媒体计算机，它需要有广播级质量的视频音频的获取和输出、压缩解压缩，实时处理和特技以及编辑功能。 
        ②用多媒体技术制作V-CD及影视音响卡拉OK机。多媒体数据压缩和解压缩技术是多媒体计算机系统中的关键技术，V-CD就是利用MPEG-I的音频编码技术将声音压缩到原来的六分之一。 
        ③采用多媒体技术创造PIC（个人信息通信中心），即采用多媒体技术使一台个人计算机具有录音电话机、可视电话机、图文传真机、立体声音向设备、电视机和录像机等多种功能 
        ，即完成通信、娱乐和计算机的功能。如果计算机再配备丰富的软件联接上网，还可以完成许多功能进一步提高用户的工作效率。 <br>
        <br>
        <b>问答第12题</b><br>
        计算机产业的发展趋势应该是把多媒体和通信的功能集成到CPU芯片中，过去计算机结构设计较多地考虑计算功能，主要用于数学运算及数值处理，最近几年随着多媒体技术和网络通信技术，需要计算机具有综合处理声、文、图信息及通信的功能。经过大量的实验分析多媒体信息的实时处理、压缩编码算法及通信，大量运行的是8位和16位定点矩阵运算。把这些功能和算法集成到CUP芯片中要遵循下述几条原则： 
        ① 压缩的算法采用国际标准的设计原则； ② 多媒体功能的单独解决变成集中解决； ③ 体系结构设计和算法相结合。 为了使计算机能够实时处理多媒体信息，对多媒体数据进行压缩编码和解码，最早的解决办法是采用专用芯片，设计制造专用的接口卡。最佳的方案应该把上述功能集成到CPU芯片中。从目前的发展趋势看可以把这种芯片分成两类：一类是以多媒体和通信功能为主，融合CPU芯片原有的计算功能，它的设计目标是用在多媒体专用设备，家电及宽带通信设备，可以取代这些设备中的CPU及大量Asic和其它芯片。另一类是以通用CPU计算功能为主，融合多媒体和通信功能，它们的设计目标是与现有的计算机系列兼容，同时具有多媒体和通信功能，主要用在多媒体计算机中。 
        <br>
        <br>
        <b>问答第13题</b><br>
        JPEG静态图像压缩编码主要原及实现技术概述为以下几点： ① 离散余弦变换（DCT） 首先把一幅图像（单色图像的灰度值或彩色图像的亮度分量或色差分量信号）分成8×8的块按图中的框图进行离散余弦正变换（FDCT）和离散余弦逆变换（IDCT）。 
        ② 量化 为了达到压缩数据的目的，对DCT系数F（u,v）需作量化处理。量化处理是一个多到一的映射它是造成DCT编解码信息损失的根源。在JPEG标准中采用线性均匀量化器。量化定义为，对64个DCT变换系数F（u,v）除以量化步长Q(u,v)后四舍五入取整。 
        ③ 熵编码 为进一步达到压缩数据的目的，需对量化后的DC系数和行程编码后的AC系数进行基于统计特性的熵编码。63个AC系数行程编码和码字，可用两个字节表示。JPEG建议使用两种熵编码方法：Huffman编码和自适应二进制算术编码。熵编码可分成两步进行，首先把DC和AC系数转换成一个中间格式的符号序列，第二步是给这些符号赋以变长码字。 
        <br>
        <br>
        <b>问答第14题</b><br>
        DVI系统能够用计算机综合处理声、文、图信息。 从硬件方面看： ① 选用了PLV（Product Leave Video）视频压缩编码算法，产生AVI文件。 
        ② 为了实现PLV算法，DVI系统设计制造了两个专用芯片82750 PA（PB）（像素处理器）和82750 DA（DB）（显示处理器）。 ③	
        同时设计了三个专用的门阵电路，即82750 LH（主机接口门阵）、82750 LV（VRAM/SCSI/Capture接口门阵）和82750 
        LA（音频子系统接口门阵）。 ④ 设计实现了AVE（视频音频引擎）。 从软件方面看： DVI系统设计实现了DOS环境下的AVSS（Audio 
        Video Sub System）和Windows环境下的AVK（Audio Video Kernel），DVI系统中最成功的部分是AVE（视频音频引擎）。AVE包括三个部分，即视频子系统、音频子系统和AVBUS（视频音频总线）。 
        DVI系统比较成功地解决了声、文、图信息的综合处理问题。它是一个比较成熟的多媒体计算机系统，它获得了"Comdex 91"最佳多媒体产品奖和最佳展示奖。 
        DVI系统失败的地方是：由于现行的视频压缩国际标准是H.261、H.263、MPEG-1、MPEG-2，而DVI的视频压缩算法采用非国际标准（AVI文件），这便是它的失败之处。 
        理想系统设计和实现： ① 采用国际标准的设计原则 标准化是产业活动成功的前提，为了使新型的计算机增加多媒体数 据的获取、压缩和解压缩、实时处理和特技、输出和通信等功能，设计时必须采用国际标准。如视频的H.261、H.262、H.263、MPEG-1、MPEG-2，音频的国际标准有G.711、G.712、G.722、G.723、G.728、G.729。 
        ② 多媒体和通信功能的单独解决变成集中解决 计算机综合处理声、文、图信息和通信功能，过去的解决办法是设计专用接口卡分散单独解决，例如使用类似声霸卡解决声音的输入输出和实时编码、解码及处理问题，使用视频压缩编码和解码卡解决视频信号压缩和解压缩问题等。现在希望采用微码引擎，设计制造合适的DSP或阵列处理器通过微码编程综合解决这些问题。 
        ③ 体系结构设计和算法相结合 要想使计算机具有综合处理声、文、图信息和通信功能的最佳解决办法是把计算机体系结构设计和算法相结合。综合处理声、文、图信息和通信功能算法的核心是数字信号处理，数组向量运算，即以乘加运算为核心的矩阵运算。 
        ④ 把多媒体和通信技术作到CPU芯片中 多媒体计算机必须使其与网络相结合，为了使计算机具有多媒体和通信功能，最早的解决办法是采用专用芯片设计制造专用接口卡；其次是把多媒体和通信功能作到母板上，最佳的方案是将多媒体和通信功能融合到CPU芯片中。从目前的发展趋势看可以把融合方案分为两类：一类是以多媒体和通信功能为主，融合CPU芯片原有的计算功能，其设计目标是用在多媒体专用设备、家电和宽带通信设备上，可以取代这些设备中CPU及大量的ASIC及其它芯片。另一类是以通用CPU计算功能为主，融合多媒体和通信功能，它们的设计目标与现有计算机系列兼容，融合多媒体和通信功能，主要用在多媒体计算机中。 
        <br>
        <br>
        <b>问答第15题</b><br>
        视频会议（Video Conference）系统是一种新型的通信手段，它可以点对点通信，也可以多点对多点的通信，它在同一传输线路上承载了多种媒体信息：视频、音频和数据等，实现多点实时交互式通信，同时也可以将不同地点与会人员的活动情况、会议内容以及各种文件以可视新闻的形式展现在各个分会场，这是一种快速高效、日益增长、广泛应用的新的通信业务。它的主要组成部分是：综合业务多媒体终端、多点控制单元MCU(Multipoint 
        Contral Unit)、信道（网络）、控制管理软件（Qos-Quality of Service）保证、资源的调度和协商、安全保密。<br>
        <br>
        <b>问答第16题</b><br>
        国际电报电话咨询委员会CCITT的第XV研究小组于1984年组建了一个关于可视电话编码的特别小组，它的目标是建立一个传输率为m×384kbps（m=1，2，…，5）的视频编码标准。后来经过充分的研究和论证，CCITT建议草案H.261可用于传输率在P×64kbps（n=1，2，…，30）的视听服务的视频编码器，终于于1990年12月完成并予通过，H.261成为正式的视频图像压缩编码的国际标准。 
        该标准主要用于采用综合业务数字网ISDN(Integrated Service Digital Netware)的各个领域，如可视电话和视频会议等。H.261的压缩编码方法，帧内压缩编码方法与JPEG相似，不同的是它采用公用中间格式CIF(Common 
        Intermediate Format) 288*360和1/4公用中间格式QCIF(Quarter Common Intermediate 
        Format) 144*180,并采用帧间预测和运动估计进行帧间压缩。 <br>
        <br>
        <b>问答第17题</b><br>
        黑白全电视信号由三部分组成：图像信号、复合消隐信号（行消隐和场消隐）和复合同步信号（行同步和场同步）。 它由图像信号（亮度信号、色度信号）、复合消隐信号（包括行消隐和场消隐信号）、 
        复合同步信号（包括行同步和场同步信号）等叠加在一起组成的。 从时间上看一行是64μs，正程是52.2μs，逆程（消隐）是11.8μs，其中有同步信号4.7μs，一帧是625行，40ms,分奇数场和偶数场。 
        从幅度上看，全电视信号峰峰值是1V，同步信号为100%，黑电平和消隐电平为70%，白电平为0%，图像信号介于白电平和黑电平之间，根据图像颜色而变化。 
        <br>
        <br>
        <b>问答第18题</b><br>
        在多媒体计算机中利用查找表解决视频信号实时处理问题。常用的有一维和二维查找表，它们是用ROM和RAM实现的函数变换，在我们课程中常遇到的sin/cos表、对数、反对数、求反、二值化及直方图均衡化都可用一维查找表实时实现，简单的乘法可以用二维查找表完成。<br>
      </td>
  </tr>
</table>
  </center>

</body>
</html>
