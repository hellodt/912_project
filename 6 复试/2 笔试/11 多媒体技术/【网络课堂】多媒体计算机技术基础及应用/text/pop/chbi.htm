<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<title>词汇表</title>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<link rel="stylesheet" href="../../css/text.css" type="text/css">
</head>

<body background="../../images/templater/pop/di.gif" leftmargin="5" topmargin="5" bgproperties=fixed marginwidth="0" marginheight="0">
<table width="100%" border="0" cellpadding="0" cellspacing="0">
  <tr> 
    <td valign="top" class="text"> 　　<b>1. 媒体（Medium）</b><br>
      　　在计算机领域中有两种含义，一是指用以存储信息的实体，如磁带、磁盘、光盘和半导体存储器；一是指信息的载体，如数字、文字、声音、图形和图像。多媒体技术中的媒体是指后者。<br>
      　　<b>2. 多媒体（Multimedia）</b><br>
      　　多媒体译自英文的&quot;multimedia&quot;，multimedia是20世纪80年代初产生的一个英文名词。1976年首次用到&quot;Multiple 
      Media&quot;一词，其中&quot;Multiple&quot;的意思是明确的，是&quot;多&quot;的意思，&quot;Media&quot;是&quot;Medium&quot;的复数形式。多媒体是指多种媒体信息，如数字、文字、声音、图形、图像、视频和动画等。到了80年代就把这两个词复合成&quot;multi-media&quot;，用得多了之后就写成&quot;multimedia&quot;。与multimedia对应的一词是monomedia，其中mono是&quot;单一&quot;的意思。<br>
      　　<b>3. 多媒体计算机技术（Multimedia Computing）</b><br>
      　　计算机综合处理多种媒体信息：文本、图形、图像、音频和视频，使多种信息建立逻辑连接，集成为一个系统并具有交互性。<br>
      　　简单地说：<br>
      　　(1)计算机综合处理声、文、图信息；<br>
      　　(2)具有集成性和交互性。<br>
      　　<b>4. CD-I(Compact Disc-Interactive)系统</b><br>
      　　早期卓有成效的多媒体计算机系统之一。 由Philips/Sony公司研制开发，1986年4月在光盘国际会议首次公布和演示了基本的CD-I系统，受到好评，同时还公布了CD-ROM文件格式，这就是以后的ISO标准。CD-I音频系统采用ADPCM压缩编码方法，CD-I视频子系统采用了一维DYUV编码、RGB 
      5:5:5编码、CLUT(Color Look-Up Table)编码及一维行程编码。CD-I的图象是由四个图像平面组成：一个彩色游标平面、两个全屏幕图像平面及一个背景平面。在软件控制下，这些平面上的图可以按各种要求叠加生成一幅画面显示在光屏上。<br>
      　　<b>5. DVI(Digital Video Interactive)系统</b><br>
      　　RCA公司的戴维・沙诺夫研究中心（David Sanaoff Research Center in Princeton，New Jersey）于1983年开始了DVI技术的研究开发工作，在1987年3月第二次Microsoft 
      CD-ROM会议上，首次公布了DVI技术的研究成果，1988年10月Intel公司从GE公司买来了DVI技术，1989年Intel和IBM公司在国际市场上推出了DVI技术的第一代产品Action 
      Media 750，1991年又在美国comdex展示会上推出了第二代的DVI技术的产品Action Media 750Ⅱ。该产品荣获Comdex 
      91最佳展示奖和最佳多媒体产品奖。该产品采用了PLV(Product Level Video)视频压缩编码算法；设计了两个专用芯片（82750 
      PB象素处理器及82750 DB显示处理器）；设计制造了三块门阵电路：82750LH主机接口门阵、82750LV VRAM/SCSI/capture接口门阵、82750LA音频子系统接口门阵；首次设计了视频音频引擎 
      (AVE-Audio Video Engine)；开发了多媒体计算机软件系统： AVSS(Audio Video Sub-System)和 AVK(Audio 
      Video Kernel)。<br>
      　　<b>6. 个人信息通讯中心（PIC-Personal Information Communication Centre）</b><br>
      　　由于采用多媒体技术，使一台联网的计算机具有录音电话机、可视电话机、图文传真机、多媒体E-mail、立体声音响设备、电视机和录像机等多种功能，有人称其为个人信息通信中心。它是现有PAC-Personal 
      Activity Centre和PDA-Personal Digital Assistant的发展方向。<br>
      　　<b>7.彩色空间</b><br>
      　　自然界常见的各颜彩色光都可以由红（R）、绿（G）、蓝（B）三种颜色光按不同比例相配而成，同样各种颜色也可以分解成红、绿、蓝三种色光，这就是色度学中最基本原理--三基色原理。当然三基色的选择不是唯一的。在多媒体计算机中常见的彩色空间如下：<br>
      　　(1)RGB彩色空间：计算机的监视器的输入和电视机显示输出都需要RGB三个分量；<br>
      　　(2)YUV和YIQ彩色空间：PAL制式彩色电视使用YUV彩色空间，Y是亮度， U V是色差信号， NTSC制式采用 YIQ彩色空间，Y是亮度， 
      I Q也是色差。它们之间的关系是：<br>
      　　<img src="../../images/chatp/pop/001.gif" width="172" height="53"> <br>
      　　<img src="../../images/chatp/pop/002.gif" width="244" height="75"> <br>
      　　<b>8. 黑白全电视信号</b><br>
      　　黑白全电视信号由三部分组成：图像信号、复合消隐信号（行消隐和场消隐）和复合同步信号（行同步和场同步）。 从时间上看一行是64μs，正程是52.2μs，逆程（消隐）是11.8μs，其中有同步信号4.7μs，一帧是625行，40ms,分奇数场和偶数场。从幅度上看，全电视信号峰峰值是1V，同步信号为100%，黑电平和消隐电平为70%，白电平为0%，图像信号介于白电平和黑电平之间，根据图像灰度而变化。<br>
      　　<b>9. 彩色全电视信号</b><br>
      　　在现代彩色电视系统中，通常采用YUV彩色空间和YIQ颜色空间，Y为亮度信号，它可以和黑白全电视信号兼容，U V和I Q 为色差信号。我们以我国使用的PLA制式为例。U 
      V用副载波频率ωSC调制加到亮度信号Y上，最后形成彩色全电视信号，可用如下简化表达式： <br>
      　<img src="../../images/chatp/pop/003.gif" width="287" height="75"> <br>
      　　<b>10. 离散时间振荡器（DTO-Discrete Time Oscillitor）</b><br>
      　　 在数字锁相回路中用离散时间振荡器，可以改变振荡器振荡频率。它的核心部件是加法器，加法器的输出通过一个寄存器反馈到加法器输入端，和另一个输入增量P相加，当和超过加法器最大值q时，产生溢出和进位，经过推导可以证明，增量P和进位的频率f。成正比。 
      <br>
      　　<b>11. 数字锁相</b> <br>
      　　采用数字电路原理使离散时间振荡器的振荡频率和输入频率一致。数字锁相回路主要由数字式检相器、数字式滤波器、离散时间振荡器和数字式分频器组成。<br>
      　　<b>12. 数字解码</b><br>
      　　彩色全电视信号数字化后，得到数字式彩色全电视信号，一路经过数字式彩色副载波陷波滤波器，得到数字式色差信号U V ；再经过数字式U V解调电路，分别得到数字式U和V信号，这就是彩色全电视信号的数字解码。<br>
      　　<b>13. 彩色键联（Color Key）</b> <br>
      　　视频获取器的视频信号和VGA卡计算机输出信号的合成是通过彩色键联信号完成的。我们可以在计算机VGA卡定义一个显示窗口，再在这个窗口中定义一个彩色键联值，即某一个颜色，当在VGA卡中出现这个颜色时，在窗口中显示的是当时的视频信号信息，这样就将视频信号和VGA卡信号合成在一起。<br>
      　　<b>14. 查找表（LUT-Look Up Table）</b> <br>
      　　在多媒体计算机中利用查找表解决视频信号实时处理问题。常用的有一维和二维查找表，它们是用ROM和RAM实现的函数变换，在我们课程中常遇到的sin/cos表、对数、反对数、求反、二值化及直方图均衡化都可用一维查找表实时实现，简单的乘法可以用二维查找表完成。<br>
      　　<b>15. 调色板（Pallette）</b> <br>
      　　调色板是显示技术中使用的一个查找表。如在显示缓存中可以存颜色的代码（4位或8位），输出时通过调色板将颜色的代码转换成24位真彩色。调色板可以用RAM实现，输入8位颜色代码，就是RAM的8位地址，每个存储器的字长是24位真彩色。这样经过调色板就可以实现8位颜色代码到24位真彩色的转换。<br>
      　　<b>16. 图像文件格式</b> <br>
      　　数字式图形、图像及视频信息，都以文件的形式存储到计算机的存储器，我们希望能有国际标准的文件格式，但是目前还不全是，大多数是工厂或企业的标准。通常将其分成两类，一类是静态图像文件格式；另一类是动态视频图像文件格式。我们课件中介绍了六种静态图像文件格式：GIF- 
      Graphics Interchange Format、TIFF- Tag Image File Format、TGA- Tag Image File 
      Format、BMP-Bitmap、PCX和MMP及两种动态视频图像文件格式：MGP和AVI。<br>
      　　<b>17. 数字音频</b> <br>
      　　将声音连续电压表示，经过离散化的采样和量化变成数字表示，称之为数字音频。<br>
      　　<b>18. 音频文件格式</b> <br>
      　　数字式音频信息都以文件的形式存储到计算机的存储器中，我们课件中给出了下述音频文件格式：<br>
      　　文件扩展名 　　　简要说明.<br>
      　　PCM PCM　　　　 （脉冲码调制）<br>
      　　VOC creative　　公司波形音频文件格式<br>
      　　WAV Microsoft　 公司的波形音频文件格式.<br>
      　　SND NeXT　　　　计算机的波形文件格式.<br>
      　　AIF Apple　　　 计算机的波形文件格式.<br>
      　　MID 　　　　　　MIDI文件格式.<br>
      　　RMI　　　　　　 Microsoft公司的MIDI文件格式<br>
      　　<b>19. 音频编码国际标准</b> <br>
      　　国际电报电话咨询委员会（CCITT）和国际标准化组织（ISO）先后提出了系列有关音频编码的国际标准和建议。1972年首先制定了G.711 64Kbps 
      （Aμ）<b>→</b>（Aμ）律PCM编码标准。1984年又公布了G.721标准（1986年修订）。它采用的自适应差值脉冲编码（ADPCM），数据率为32Kb／s。针对宽带语音（50～7KHz），CCITT制定了G.722编码标准，它的数据率为64Kb/s。之后又公布了G.723建议码率为５.3kb/s和6.3kb/s, 
      G.726的码率为16kb／s。CCITT于1990年通过了16-40kb／s镶嵌式ADPCM标准G.727。CCITT在1992年和1993年分别公布了浮点和定点算法的G.728标准。ISO的运动图像专家组（MPEG）,为图像伴音制定了20KHZ带宽的128Kb／s标准。<br>
      　　<b>20. AC-3 </b><br>
      　　美国杜比公司（Dolby）制定的环境立体声音频压缩编码标准，它在制定了AC-1和AC-2后又制定了AC-3。AC-3采用了频谱分析技术，非线性子带带宽分配、动态时域／谱域带宽分配、心理声学模型和多声道耦合技术，具有很高的数据压缩率和很低的失真度。杜比AC-3有完全独立的６个声道，全频带的左、右、中、左环绕、又环绕和一个低于120HZ的超低音，因此，又称为5.1声道。 
      <br>
      　　<b>21. 文语转换系统</b>　<br>
      　　TTS-Text to Speech文语转换(TTS)是一种智能型的语言合成，它涉及到语言学、语音学、语音信号处理、心理学等多个领域。它综合了多学科的研究成果，将文字转换成声音，解决计算机言语输出问题。清华大学计算机系设计实现的汉语TTS系统Sonic主要由四个模块组成: 
      语言学处理、语音学处理、波形编辑合成和安装程序。<br>
      　　<b>22. MIDI(Musical Instrument Digital Interface)</b><br>
      　　MIDI是乐器数字接口的缩写，它始建于1982年，MIDI泛指数字乐器接口国际标准。标准的多媒体PC平台能够通过内部合成器或连到计算机端口的外部合成器播放MIDI文件。MIDI标准规定了不同厂家的电子乐器与计算机连接的电缆和硬件。它还指定了从一个装置传送数据到另一个装置的通信协议。这样，任何电子乐器，只要有处理MIDI信息的处理器和适当的硬件接口都能变成MIDI装置。 
      MIDI间靠这个接口传递消息(massage)，消息是乐谱(Score)的数字描述。乐谱由音符序列、定时和合成音色(Patches)的乐器定义所组成。当一组MIDI消息通过音乐合成芯片演奏时，合成器解释这些符号，并产生音乐。<br>
      　　<b>23. 语音识别</b><br>
      　　语音识别是计算机将人发出的声音、字或短语转换成文字、符号或给出响应、作出回答。口语是最自然的人机交互方式，让说话替代键盘输入汉字是中国人使用计算机者的愿望。它正在变成现实，其技术基础就是语音识别和理解。语音识别系统可分为大、中、小词汇量三种。词汇量少于100的称为小词表语言识别；大于1000的称为大词表语音识别；中间称为中词表语音识别系统，语音识别系统也可按输入方式分成：孤立词、连接词和连续词语音识别系统，也可按说话人分成特定人、限定人和非特定人语音识别系统。<br>
      　　<b>24. 量化数据</b><br>
      　　压缩编码中的量化不是A/D变换后的量化，但是它是数据比特率下降最有力的方法。它是以PCM码作为输入，经正交变换、差分或预测处理后，在熵编码之前，对正交变换系数、差值或预测误差以量化处理。量化输入值的动态范围很大，需要以多的比特数表示一个数值，量化输出只能取有限个整数，称作为量化级，希望量化后的数值用较少的比特数便可表示。每个量化输入被强行归一到与其接近的某个输出，即量化到某个级。量化处理总是把一批输入量化到一个输出级上，所以量化处理是一个多对一的处理过程，是一个不可逆的过程，量化处理有信息丢失，或者说会引起量化误差（量化噪声）。<br>
      　　<b>25. 霍夫曼编码</b> <br>
      　　霍夫曼（Huffman）编码方法于1952年问世，现在广泛地用在各种数据压缩技术中，它是熵编码中最佳编码方法。霍夫曼编码的理论依据是变字长编码理论。在变字长编码中，编码器按输入信源符号出现的统计概率，给输出码字分配以不同的字长。对于编码输入时，出现大概率的信源符号，赋以短字长的输出码字；对于编码输入时，出现的小概率信源符号，赋以长字长的输出码字。可以证明，按照概率出现大小的顺序，对输出码字分配不同码字长度的变字长编码方法，其输出码字的平均码长最短，与信源熵值最接近，编码方法最佳。<br>
      　　<b>26. 行程编码</b> <br>
      　　行程编码（Run Length Code）也称行程长度编码。行程编码是无失真压缩编码方法。行程编码原理是建筑在图像统计特性基础上。对于黑白二值图像，由于图像的相关性，每一行扫描线总是由若干段连续的象素点和连续出现的白象素点构成。黑（白）象素点连续出现的象素点数称行程长度，简称长度。黑象素的长度和白象素的长度总是在交替发生，交替发生变化的频度与图的复杂度有关。现在我们把灰度1（黑）和1的行程长度，或0（白）和0的行程长度组合，构成编码输入码元而进行编码，并按其出现的概率，分配以不同码长的码字。大概率以短码；小概率以长码； 
      同样道理，对于灰度图像或彩色图像，也可以将其灰度值（或彩色值）与其行程长度组合一起作为编码输入的码元进行编码。<br>
      　　<b>27. 预测编码 </b><br>
      　　预测编码（Predictive Coding）是统计冗余数据压缩理论三个重要分支之一，它的理论基础是现代统计学和控制论，用预测编码可以减少数据时间和空间的相关性，它广泛地用于时间序列图像数据和语音数据的压缩编码。预测编码的方法是从相邻象素之间有较强的相关性特点考虑，比如当前象素的灰度或颜色信号，数值上与其相邻象素总是比较接近，除非处于边界状态，那么，当前象素的灰度或颜色信号的数值，可用前面已出现的象素的值进行预测（估计），得到一个预测值（估计值），将实际值与预测值求差，对这个差值信号进行编码、传送，这种编码方法称为预测编码方法。预测编码方法分线性预测和非线性预测编码两种。<br>
      　　<b>28. 变换编码</b> <br>
      　　变换编码不是直接对空域图像信号进行编码，而是首先将空域图像信号映射变换到另一个正交矢量空间（变换域或频域），产生一批变换系数，然后对这些变换系数进行编码处理。其中关键问题是在时域或空域描述时，数据之间相关性大，数据冗余度大，经过变换在变换域中描述，数据相关性大大减少，数据冗余量减少，参数独立，数据量少，这样再进行量化，编码就能得到较大的压缩比。目前常用的正交变换有：傅立叶 
      (Fouries)变换、沃尔什(Walsh)变换、哈尔(Haar)变换、斜(Slant)变换、余弦变换、正弦变换、K-L(Karhunen-Loeve)变换等。<br>
      　　<b>29. K－L变换</b><br>
      　　K－L (Karhunen-Loeve)是以统计特性为基础的最佳正交变换，也称为特征向量或主分量变换。1933年霍特林(Hotelling)首先发现主分量变换技术，并对这种正交变换作了深入研究。所以有人称K－L变换为霍特林变换。<br>
      　　K－L变换的优点是：<br>
      　　（1）经过K－L变换后，所得Y向量，其平均向量为0，说明Y向量坐标系已移至直流分量为零的位置。<br>
      　　（2）Y向量的协方差矩阵为对角矩阵，对角线上的元素是Y向量的方差，左上角的值最大，右上角值最小。非对角线上的元素是协方差，而协方差值均为零，说明Y向量之间的相关性很小。K－L变换的缺点是计算过程复杂，变换速度慢。<br>
      　　<b>30. DCT 变换离散余弦变换（DCT --Discrete Cosine Transform）</b><br>
      　　是傅里叶变换的一种特殊情况。在傅里叶级数展开式中，被展开的函数是实偶函数时，其傅里叶级数中只包含余弦项，称之为余弦变换。离散余弦变换的特性和K－L变换比较接近，但是DCT计算复杂性适中，又具有可分离特性，还有快速算法，所以被广泛地用在图象数据压缩编码算法中，如JPEG、MPEG-1、MPEG-2及H.261等压缩编码国际标准都采用了离散余弦变换编码算法。<br>
      　　<b>31. JPEG</b><br>
      　　国际电报电话咨询委员会(CCITT) 和国际标准化委员会(ISO)联合组合一个图像专家组JPEG（Joint Photographic Experts 
      Group），从1986年开始，多年来一直致力于研究连续色调、多级灰度、静止图像的数字图像压缩编码方法，并于1992年1月提出连续色调静止图像压缩编码国际标准ISO/IEC 
      10918,现在它被广泛地应用在多媒体计算机、通信等各个领域。基于离散余弦变换(DCT)的JPEG编码原理是：将YUV彩色图片分成8*8块，对每个8*8块进行DCT变换，得到DCT系数采用JPEG给定或自己选定的量化表进行量化，得到DC和AC系数，对AC系数进行之字型扫描，对其进行行程编码和熵编码，这样就得到了JPEG压缩图像的数据。最近几年JPEG组织又推出了基于小波变换（Wavelet 
      Transform）的JPEG-2000，它有更高的压缩比，较小的失真，现在它被成功地用在数码相机等产品中。<br>
      　　<b>32. H.261</b><br>
      　　国际电报电话咨询委员会CCITT的第XV研究小组于1984年组建了一个关于可视电话编码的特别小组，它的目标是建立一个传输率为m×384kbps（m=1，2，…，5）的视频编码标准。后来经过充分的研究和论证，CCITT建议草案H.261可用于传输率在P×64kbps（P=1，2，…，30）的视听服务的视频编码器，终于于1990年12月完成并予通过，H.261成为正式的视频图像压缩编码的国际标准。该标准主要用于采用综合业务数字网ISDN(Integrated 
      Service Digital Network)的各个领域，如可视电话和视频会议等。H.261的压缩编码方法，帧内压缩编码方法与JPEG相似，不同的是它采用公用中间格式CIF(Common 
      Intermediate Format) 288*360和1/4公用中间格式QCIF(Quarter Common Intermediate Format) 
      144*180,并采用帧间预测和运动估计进行帧间压缩。 <br>
      　　<b>33. MPEG(MPEG-1,2,4,7,21)</b><br>
      　　MPEG(Moving Picture Experts Group)运动图像专家组，在国际标准化组织ISO/IEC的领导下，从1988年MPEG委员会开始活动，1990年提出一个MPEG标准草案，1991年底提出了用于数字存储媒体的位率为1.5Mbps的运动图像及其伴音的压缩编码方案，为ISO/IEC 
      11172号建议，并于1992年正式通过，定名为MPEG-1。此后于1993年11月在汉城会议（ISO/IECJTCI/SC29/WG11）上正式通过了ISO/13813，定名为MPEG-II标准。MPEG1和MPEG2与JPEG和H.261有很多相似之处，它们也是采用了DCT、量化、行程编码和熵编码以及帧间预测和运动补偿。MPEG组织于1993年开始制定MPEG-4，1999年提出草案，2000年制定了最终国际标准，它与MPEG1、2最大区别是采用了基于内容（Object-Based）压缩编码方法。MPEG组织于1998年10月开始征集有关MPEG-7的建议，准备在2001年底正式制定出MPEG-7国际标准，它的正式名称叫作&quot;多媒体内容描述接口&quot;，它将为各种类型的多媒体信息规定一种标准化的描述，这种描述与多媒体信息的内容本身一起，支持用户对其感兴趣的各种资料进行快速、有效地检索。MPEG-21定义一个多媒体框架，解决电子内容（E-content）的传输等问题，1999年8月正式提出，1999年12月通过征集多媒体框架的技术报告（Multimedia 
      Framework）,2000年成立了MPEG-21工作组（WG）。<br>
      　　<b>34. MPC</b><br>
      　　多媒体个人计算机（Multimedia PC-MPC）并不是一个全新的个人计算机，它是在现有PC机基础上加一些硬件板卡及相应软件，使其具有综合处理声、文、图信息的功能，称之为MPC。在交互式多媒体协会IMA(Interactive 
      Multimedia Association)兼容性计划指导下，由Philips、 Microsoft、 Tandy、 NEC等14家著名厂商组成了多媒体市场协会，制定了多媒体个人计算机平台标准。实际上存在两个MPC平台标准：第一个是1991年11提出的。建立在10MHZ 
      PC 286AT基础之上，后来很快又修改为16MHZ 386SX；第二个平台标准是1993制定的，这个标准定义了第二个MPC平台标准的最小系统功能，但是并不规定它的系统结构和组成。这样有利于功能扩充和CPU的不断升级换代。 
      <br>
      　　<b>35. CD-RTOS</b> <br>
      　　CD-RTOS(Compact Disc Real Time Operating System)是由Philips 和Sony公司研制开发的CD-I的光盘实时操作系统。它源于高性能的OS-9时时操作系统，用68000汇编语言写成的，CD-RTOS是一个多任务实时操作系统，有模块化的结构，设备独立的I/O接口及能够处理多级树形结构的盘目录。它由系统相关库、CD-RTOS核、管理程序及设备驱动程序四部分组成。<br>
      　　<b>36. AVE </b><br>
      　　Intel和IBM研制开发的Ⅱ型DVI系统，荣获了&quot;Comdex 91&quot;最佳多媒体产品奖和最佳展示奖。系统中首次引进视频音频引擎AVE(Audio 
      Video Engine)的概念。AVE是由视频子系统、音频子系统、彩色键连子系统、视频音频总线、获取子系统、CD-ROM子系统及主机接口子系统七部分组成。<br>
      　　<b>37. AVSS</b> <br>
      　　它是DVI系统中的软件系统，称之为视频音频子系统AVSS(Audio Video Sub-System)。它可以在DOS支持下工作，最下层是驱动软件，一种是常驻内存的驱动器如视频驱动器、音频驱动器及多功能驱动器，一种是虚拟驱动器软件；第二层是库函数；最上层是应用层，它包括各种应用程序。<br>
      　　<b>38．AVK</b> <br>
      　　它是Ⅱ型DVI系统的软件。称之为视频音频核AVK(Audio Video Kernel)，它可以在Windows环境下工作。也可在不同操作系统支持环境下工作。它具备多层模块化结构的特点，共分四层：最下层是象素处理器微码子程序的集合，称之为&quot;微码引擎&quot;；第二层是视频音频驱动器AVD(Audio/Video 
      Driver)；第三层是视频音频库AVL(Audio/Video Library)；最上层是特定支撑环境层，它的功能是读写数据到主文件系统；把AVK集成到Windows支持的环境中。<br>
      　　<b>39. MPACT </b><br>
      　　MPACT是美国Chromatic Research公司设计开发的多媒体处理器芯片，由其合作伙伴：东芝、 LG、 SGS-Thomson等半导体厂商生产。被1996年美国微处理器论坛 
      (Micro-Processor Forum)推荐为多媒体处理器(Multimedia Processor)佼佼者。1996年2月位于美国桑尼维尔的 
      Chromatic Research公司开发的MPACT媒体处理器一经问世，华尔街邮报、今日美国、Byte杂志等数家都刊登了一系列评论，有的刊物说：&quot;媒体处理器-多媒体时代的计算机芯片。&quot;MPACT具有七种多媒体功能：视频、二维图像、三维图形、音频、传真/调制解调器、电话及视频会议，由下述七部分组成：CPU指令处理单元、多通道静态随机存储器和五个接口控制器：RDRAM接口、PCI总线接口、视频接口、显示接口及外设I/O接口。<br>
      　　<b>40. RDROM</b> <br>
      　　RDROM(Rambus DRAM)是美国Rambus公司发明的存储技术，它采用基于CMOS工艺，每片RDRAM 芯片在9bit宽的数据通道上实现了500Mb/s的传输速率。它是标准VRAM(Video 
      RAM)速率的3-5倍，是标准DRAM的速率的5-15倍。目前RDRAM有两种类型芯片：8/9Mbit(1Mbyte)容量的芯片和16/18Mbit(2Mbyte)容量的芯片，其时钟频率均为250MHZ。RDRAM的高速得益于其芯片的特殊结构，该结构被分为三层：核心层(Core 
      Layer)、逻辑层(Logic Layer)和物理层(Physical Layer)。<br>
      　　<b>41. Trimedia</b><br>
      　　Trimedia 是由Philips公司1996年推出的新一代媒体处理器（Media Processor）芯片。被1996年美国微处理器论坛（Micro-Processor 
      Forum）推荐为多媒体处理器的佼佼者。它是一款针对实时处理音频、视频、图像和通信数据流的通用微处理器，它选用了强大、通用的非常长指令字VLIW（Very 
      Long Instruction Word）的CPU和内嵌式DSP(Digital Signal Processing)相结合的方案，同时包含分离的数据和指令cache（高速缓冲存储器），峰值计算速度可达40亿次/秒。<br>
      　　它的主要结构由下述几部分组成： <br>
      　　可编程的VLIW CPU、专门的数据和指令cache、无缝的存储系统接口、高速内部总线（数据高速通路）、视频输入单元（Video In）、视频输出单元（Video 
      Out）、音频输入和输出单元(Audio In/Out)、专用的协处理器：图像协处理器ICP(Image Co-Processor)及变长解码协处理器VLD(Variable 
      Length Decoder)、I2C接口、同步串行接口SSI(Synchronous Serial Interface)及定时器等。<br>
      　　<b>42. MMX技术</b> <br>
      　　1996年3月5日Intel公司首次对外公布了MMX技术，它是由设在以色列海法的Intel实验室完成的，1997年1月9日Intel公司对外正式推出含有MMX技术，具有多媒体扩充指令集的多功能奔腾处理器P55C，1997年5月Intel又进一步推出具有MMX技术的P6奔腾芯片，主频可达300MHZ的PentiumⅡ 
      300，进一步提高了性能。MMX的核心技术是：新的数据类型、扩充的饱和型运算方式、扩充的57条新指令及与IA(Intel Architecture)结构的全兼容性。<br>
      　　<b>43. 基于内容检索</b><br>
      　　对于传统的数据库可以通过数字和关键词进行检索。但是对于多媒体数据库，它存有大量的声、文、图、动画和视频信息，光通过数字和文字进行检索显得有些不足，提出基于多媒体数据的内容进行检索，这就是基于内容检索（Content-Based 
      Retrieval）。例如：对于图像数据库可以通过形状、主颜色、纹理及轮廓等特征进行检索。基于内容检索系统由下述几部分组成：目标标识、特征提取、数据库（媒体库、特征库、知识库）、检索引擎及索引/过滤器等。<br>
      　　<b>44. 多媒体著作工具</b> <br>
      　　多媒体著作工具是指一套用于创作多媒体应用程序的软件工具，是完成制作一项和多项多媒体应用程序的计算机软件工具。目的是简化多媒体应用程序的创作过程。目前市场流行的多媒体著作工具可以分成：基于流程图如：Authorware、Icon 
      Author；基于卡片如：Action、Hypercord；基于语言如：Tool Book；基于事件驱动EDHM(Event Driver Hypermedia 
      Model)如Ark等。Ark的EDHM系统结构由下述三部分组成：数据层、文档层及表现层。 <br>
      　　<b>45. 多媒体同步方法</b> <br>
      　　协调媒体流的实时演示以及维持媒体间的时序关系称为多媒体同步。更广泛的概念应包括内容、空间和时间的关系，同步问题应考虑：同步的范畴、对象内和对象间的同步、现场同步和合成同步、以及同步的服务质量。同步定义方法有：基于时间间隔的定义法、基于时间轴的定义法、基于控制流的定义法以及基于事件的定义法。<br>
      　　<b>46. 视频会议系统</b><br>
      　　视频会议（Video Conference）系统是一种新型的通信手段，它可以点对点通信，也可以多点对多点的通信，它在同一传输线路上承载了多种媒体信息：视频、音频和数据等，实现多点实时交互式通信，同时也可以将不同地点与会人员的活动情况、会议内容以及各种文件以可视新闻的形式展现在各个分会场，这是一种快速高效、日益增长、广泛应用的新的通信业务。它的主要组成部分是：综合业务多媒体终端、多点控制单元MCU(Multipoint 
      Control Unit)、信道（网络）、控制管理软件Qos(Quality of Service）保证、资源的调度和协商、安全保密。<br>
      　　<b>47. MCU</b> <br>
      　　多点控制单元MCU（Multipoint Control Unit），视频会议系统中重要的组成部分，它可以支持不同地点多个成员协同工作，把多个地点连接起来，也可称为桥接设备，它的作用是对视频会议系统中的图像、语音、数据信号进行切换，而且是对数字式数据流进行切换。MCU对视频信号采用直接分配方式，对数据信号采用广播方式；对语音信号分两种情况：如只有一个会场发言，将其切换到其它会场；若有几个会场同时发言，MCU将其进行混合处理，挑出最高的音频信号切换到除该会场外的所有其它会场。MCU的主要组成是：网络接口单元、多路复用和解复用、视频、音频、数据、控制密钥及呼叫处理。<br>
      　　<b>48. PCS</b> <br>
      　　个人会议标准PCS(Personal Conferencing Specification)是由Intel、AT&amp;T、Lotus、HP、DEC和另外11个主流计算机软硬件公司，以及96个计算机和通信公司联合成立了一个个人会议工作组PCWG(Personal 
      Conferencing Work Group),于1994年制定了一个个人会议标准PCS。与H系列标准不同，PCS是专为个人计算机制定的会议标准，它与各种个人计算机标准兼容，包括Intel公司的Indeo编码和解码器及Microsoft公司的DVI图形/图像标准接口。<br>
      　　<b>49. 交互式电视ITV</b> <br>
      　　交互式电视ITV(Interactive Television),它是一种受观众控制的电视，在节目间和节目内观众能够作出选择决定，这是一种非对称全双工通信模式的新型电视业务。节目间(Inter 
      Program)交互式电视，可称为点播电视VOD( Video On Demand)，它又可分为真点播电视TVOD(True Video On 
      Demand)和准点播电视NVOD(Near Video OnDemand)。交互式电视系统的主要组成是：机顶盒STB(Set Top Box)、记帐计算机及用户请求计算机、视频服务器、网络和路由器。<br>
      　　<b>50. 视频服务器</b><br>
      　　视频服务器(Video Server)是交互式电视系统中最关键的组成部分，它具有：请求处理、许可控制、数据检索、可靠的流传输以及各种VCR的功能，视频服务器的结构有下述四种类型：基于PC机的视频服务器、基于高级工作站的服务器、基于专用硬件平台的视频服务以及分布式层次结构的视频服务器。视频服务器目前主要的研究问题是：磁盘数据放置和访问策略、准入控制策略、流传输技术、流调度策略、磁盘缓存策略、代理缓存策略等。<br>
      　　<b>51. 机顶盒STB</b> <br>
      　　机顶盒STB（Set Top Box）是一种消费电子（Consumer Electronics）产品，可以连接电视机，并提供附加服务的设备作为点播电视的终端，数字有线电视、数字卫星电视的终端。机顶盒有四种类型：通过有线电缆接收数据的传统机顶盒，通过电话线接收数据的机顶盒，通过DBS(Direct-Broadcast 
      Satellite)接收数据的机顶盒，第四种机顶盒就是Video-CD播放机。机顶盒的结构：系统控制、视频控制、音频控制、图形控制、网络接口及外围设备控制等。<br>
      　　<b>52. 计算机支持的协同工作</b> <br>
      　　计算机支持的协同工作CSCW(Computer Supported Cooperative Work)最早是由Grief和Cashman在1984年提出的，用于描述他们正在组织的如何利用计算机支持交叉学科研究人员共同工作的课题。CSCW系统有两个本质特征：共同任务和共享环境。一般应具有下述三种活动：通信，协同工作者间进行信息交换；合作，群体协同共同完成某项任务；协调，对协同工作进行协调。通用CSCW系统的层次结构：分布环境与服务（联网的计算机系统）、CSCW支撑平台、各种CSCW应用程序及用户界面。 
      <br>
    </td>
  </tr>
</table>
</body>
</html>
