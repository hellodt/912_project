<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><!-- InstanceBegin template="/Templates/frame_content.dwt" codeOutsideHTMLIsLocked="false" -->
<head>
<!-- InstanceBeginEditable name="doctitle" -->
<title>Untitled Document</title>
<!-- InstanceEndEditable --> 
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<!-- InstanceBeginEditable name="head" -->
<!-- InstanceEndEditable --> 
<link href="../../css/fc.css" rel="stylesheet" type="text/css">
<style type="text/css">
<!--
.bg {
	background-image: url(../../images/images/main__11.gif);
	background-position: right bottom;
	background-repeat: no-repeat;
	background-attachment: fixed;
}
-->
</style>
</head>

<body >
<table width="100%" height="100%" border="0" cellpadding="4" cellspacing="0">
  <tr>
    <td valign="top"><!-- InstanceBeginEditable name="text" --> 
      <p class="FCcontent"><span class="FCtitle1"><strong>6.4.1 引言</strong></span><br>
        　　在6.1中讨论人工神经网络的历史时，就提到感知器只能对特征空间进行线性划分，因而它无法执行诸如异或(XOR)或奇偶校验等并不复杂的运算。人们也早就发现，如果在输入端与输出结点之间引入隐含层，则上述一些运算的执行就不成问题了，这就是本节要讨论的多层前馈网络。网络呈现分层的结构，如图6-9所示。外界信号从输入端子经加权传送到隐含层，在隐含层中运算后，又从其输出经加权送到下一层，直至将复杂的运算结果反映到输出结点的输出端上。问题在于在人工神经网络研究的早期，人们还不知道如何用训练方式确定含隐含层结点网络的所有参数，因而使人工神经网络的研究走向沉寂。<br>
        　　八十年代初，随着对人工神经网络研究的兴趣的复兴，人们对多层前馈网络的性能，尤其是训练方法着力进行研究，许多人对此进行了彼此独立的研究，并于1985年前后分别发表了基于误差回传的训练算法，从而在原理上解决了多层网格的训练问题，使得这种类型的网络成为人工神经网络模型中应用最为普遍的一种。本节将首先讨论多层网结构的特点及其基本性能，然后讨论典型的误差回传算法(Back-Propagation 
        Algorithm)又称BP算法，最后再讨论其若干典型应用。</p>
      <!-- InstanceEndEditable --></td>
  </tr>
</table>
</body>
<!-- InstanceEnd --></html>
