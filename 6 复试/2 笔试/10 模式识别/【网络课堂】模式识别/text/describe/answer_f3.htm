<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<title>课程简介</title>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<link href="../../css/fc.css" rel="stylesheet" type="text/css">
</head>

<body background="../../images/image_temp/sub_block.gif">
<table width="100%" border="0" cellspacing="0" cellpadding="8">
  <tr>
    <td class="FCcontent"> <span class="questiontitle">13．剪辑近邻法中要把原样本集划分成一个测试集和一个训练集，“这两个子集的分布要相互独立”怎样理解？</span><br>
      　　答：剪辑近邻法要在保持原样本集分布的条件下开始剪辑，在划分子集时就必须让两个子集保持原样本集的分布，这才可能模拟原样本集分布条件下对样本集进行剪辑。要求分成两子集时,注意保证原样本集分布不变，因此对这两个子集来说叫分布相互独立，哪一个子集也不会因为另一个子集而改变了子集的分布。 
      <p><span class="questiontitle">14．Fisher准则方法与支持向量机提出的最佳准则是不一致的，它们是否有各自适用的范围？</span><br>
        　　答：在学模式识别这门课时要时刻记住的一点是，最佳是相对于某一个准则而言的。因此有时不便于对不同的分类器设计方法进行比较。Fisher准则已有很长历史，也经常得到应用。支持向量机是在对泛化误差研究的基础上提出的，实际中也有好的评价，是近年来比较推崇的一种方法。但对于一个具体问题来说，还不能肯定的说哪一种方法好。</p>
      <p><span class="questiontitle">15．能不能对特征提取进一步解释一下？</span><br>
        　　答：特征提取是模式识别中一项最重要的环节，提取出对分类有效的特征是设计分类器成败的关键。目前来说也是设计者智慧最集中体现的环节。一般说来特征提取与所研究的问题密切相关，也没有一个可以现成套用的方法，而第四章讲的只是利用一些数学工具，如线性变换进行特征提取的通用方法，是在已有特征空间基础上的改进。</p>
      <p><span class="questiontitle">16．有没有对特征提取的通用评价方法？</span><br>
        　　答：对分类器性能最主要的评价是错分率，因此对特征提取的评价应该与错分率联系起来。统计模式识别的基本方法是将特征空间划分成不同的决策域，如果被测试的某类样本进入了属于另一类的决策域，就出现错分。因此希望不同类的样本在特征空间中的分布呈现紧致性。例如手写的同一个汉字形状可以变化很大，如果特征选择得不合适，就会使不同的字在特征空间中混迭起来。这就是数据的紧致性差。选择抗变异性强的特征，反映该类别本质的特征可起到紧致性好的效果。</p>
      <p><span class="questiontitle">17．K-L变换的降维作用与在信息压缩中的作用是否是一回事？</span><br>
        　　答：是，K-L变换是做到在降至同样维数时,信号的截尾误差最小，也就是说保留了原空间中绝大部分信息，这样一来就可在一个维数较低的特征空间中,讨论模式识别的问题。正是由于K-L变换有这样的性质，才可以用到信息压缩中去。<br>
      </p></td>
  </tr>
</table>
</body>
</html>
